# -*- coding: utf-8 -*-

import os
import re
import glob
import polars as pl
import pandas as pd
from datetime import datetime
import calendar
from tqdm import tqdm
import warnings
import contextlib
import io
import unicodedata
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor

# ==========================================================
# ðŸ“‚ Caminhos
# ==========================================================
BASE_ROOT = r"C:\Users\J&T-099\OneDrive - Speed Rabbit Express Ltda (1)\Ãrea de Trabalho\Testes\Politicas de BonificaÃ§Ã£o"

DIR_COLETA = os.path.join(BASE_ROOT, "00 -  Base de Dados (Coleta + ExpediÃ§Ã£o)")
DIR_T0 = os.path.join(BASE_ROOT, "01 - Taxa de entrega T0")
DIR_RESS = os.path.join(BASE_ROOT, "02 - Ressarcimento por pacote")
DIR_SHIP = os.path.join(BASE_ROOT, "03 - ReduÃ§Ã£o Shipping Time")  # (nÃ£o usado ainda, mantido)
DIR_ANTIGA = os.path.join(BASE_ROOT, "Base Antiga")  # (nÃ£o usado ainda, mantido)
DIR_SEMMOV = os.path.join(BASE_ROOT, "05 - Pacotes Sem MovimentaÃ§Ã£o")
DIR_RETIDOS = os.path.join(BASE_ROOT, "06 - Retidos")
DIR_DEVOLUCAO = os.path.join(BASE_ROOT, "00.3 - Base DevoluÃ§Ã£o")
DIR_PROBLEMATICOS = os.path.join(BASE_ROOT, "00.2 - Base de Problematicos (GestÃ£o de Anormalidade)")
DIR_CUSTODIA = os.path.join(BASE_ROOT, "00.4 - Base Custodia")
DIR_BASE_LISTA = os.path.join(BASE_ROOT, "00.1 - Base Retidos(Lista)")  # (nÃ£o usado agora)

# Coordenadores agora por pasta
DIR_COORDENADOR = r"C:\Users\J&T-099\OneDrive - Speed Rabbit Express Ltda (1)\Ãrea de Trabalho\Testes\Coordenador"

DIR_OUT = os.path.join(BASE_ROOT, "Resultados")
os.makedirs(DIR_OUT, exist_ok=True)

# ==========================================================
# âš™ï¸ ConfiguraÃ§Ãµes
# ==========================================================
REGIONAIS_DESEJADAS = ["GP", "PA", "GO"]
PRAZO_CUSTODIA_DIAS = 9
EXCEL_ROW_LIMIT = 1_048_000
GERAR_DETALHADO_RETIDOS = True


# ==========================================================
# âš™ï¸ UtilitÃ¡rios
# ==========================================================

def _normalize_strong(texto: str) -> str:
    """NormalizaÃ§Ã£o forte para bases: mantÃ©m nÃºmeros e hÃ­fens."""
    if not texto:
        return ""
    texto = str(texto).upper()
    texto = unicodedata.normalize('NFKD', texto).encode('ASCII', 'ignore').decode('ASCII')
    texto = re.sub(r'[^A-Z0-9\s-]', '', texto)
    texto = re.sub(r'\s+', ' ', texto).strip()
    return texto


def _normalize_base(df: pl.DataFrame) -> pl.DataFrame:
    if "Nome da base" not in df.columns or df.is_empty():
        return df
    return df.with_columns(
        pl.col("Nome da base")
        .map_elements(_normalize_strong, return_dtype=pl.Utf8)
        .alias("Nome da base")
    )


def diagnosticar_normalizacao():
    print("\n==============================")
    print("ðŸ” DIAGNÃ“STICO DE NORMALIZAÃ‡ÃƒO")
    print("==============================")

    arquivos = [f for f in os.listdir(DIR_COLETA) if f.endswith((".xlsx", ".xls"))]
    if not arquivos:
        print("âŒ Nenhum arquivo de Coleta encontrado para diagnosticar.")
        return

    path_arquivo = os.path.join(DIR_COLETA, arquivos[0])
    df_raw = read_excel_silent(path_arquivo)

    if df_raw.is_empty() or "Nome da base" not in df_raw.columns and "Nome da base de entrega" not in df_raw.columns:
        print("âŒ O arquivo de Coleta nÃ£o possui uma coluna de base identificÃ¡vel.")
        return

    col_base = "Nome da base" if "Nome da base" in df_raw.columns else "Nome da base de entrega"
    nomes_originais = sorted([str(n) for n in df_raw[col_base].unique().to_list() if n])

    df_normalizado = df_raw.rename({col_base: "Nome da base"}).pipe(_normalize_base)
    nomes_normalizados = sorted([str(n) for n in df_normalizado["Nome da base"].unique().to_list() if n])

    print(f"ðŸ“Š Arquivo analisado: {os.path.basename(path_arquivo)}")
    print(f"   - Nomes de base Ãºnicos ORIGINAIS: {len(nomes_originais)}")
    print(f"   - Nomes de base Ãºnicos NORMALIZADOS: {len(nomes_normalizados)}")
    print(f"\nðŸ” ReduÃ§Ã£o de {len(nomes_originais) - len(nomes_normalizados)} nomes apÃ³s a normalizaÃ§Ã£o.")

    mapeamento = defaultdict(list)
    for nome_original in nomes_originais:
        nome_normalizado = _normalize_strong(nome_original)
        mapeamento[nome_normalizado].append(nome_original)

    print("\nðŸ“Œ Exemplos de nomes que foram mesclados (se houver):")
    mesclados = {k: v for k, v in mapeamento.items() if len(v) > 1}
    if not mesclados:
        print("   âœ… Nenhum nome de base foi mesclado. A normalizaÃ§Ã£o parece segura.")
    else:
        count = 0
        for nome_final, lista_originais in mesclados.items():
            if count >= 10:
                print("   ... (e mais)")
                break
            print(f"   - {lista_originais}  --->  '{nome_final}'")
            count += 1

    print("==============================\n")


def _fix_key_cols(df: pl.DataFrame) -> pl.DataFrame:
    if df.is_empty():
        return df
    cols = df.columns
    key_aliases = [c for c in cols if c.startswith("Nome da base")]
    if not key_aliases:
        return df
    chosen = "Nome da base" if "Nome da base" in key_aliases else (
        "Nome da base_left" if "Nome da base_left" in key_aliases else (
            "Nome da base_right" if "Nome da base_right" in key_aliases else key_aliases[0]
        )
    )
    if chosen != "Nome da base":
        df = df.rename({chosen: "Nome da base"})
    for c in key_aliases:
        if c != "Nome da base" and c in df.columns:
            df = df.drop(c)
    return df


def _safe_full_join(left: pl.DataFrame, right: pl.DataFrame) -> pl.DataFrame:
    if left.is_empty() and right.is_empty():
        return pl.DataFrame()

    left = _fix_key_cols(left)
    right = _fix_key_cols(right)

    if "Nome da base" not in left.columns and "Nome da base" in right.columns:
        left, right = right, left

    if "Nome da base" not in left.columns:
        return pl.concat([left, right], how="diagonal_relaxed").unique(maintain_order=True)

    if "Nome da base" not in right.columns:
        out = left
    else:
        out = left.join(right, on="Nome da base", how="full", suffix="_dup")

    out = _fix_key_cols(out)
    dup_cols = [c for c in out.columns if c.endswith("_dup")]
    if dup_cols:
        drop = []
        for c in dup_cols:
            base = c[:-4]
            if base in out.columns:
                drop.append(c)
        if drop:
            out = out.drop(drop)

    return out.unique(subset=["Nome da base"], keep="first")


def to_float(col):
    return pl.col(col).cast(pl.Float64, strict=False).fill_null(0).fill_nan(0)


def read_excel_silent(path):
    with warnings.catch_warnings(), contextlib.redirect_stdout(io.StringIO()), contextlib.redirect_stderr(
            io.StringIO()):
        warnings.simplefilter("ignore")
        try:
            df = pl.read_excel(path)
            if all("__UNNAMED__" in c or c == "ResponsÃ¡veis" for c in df.columns):
                df = pl.read_excel(path, has_header=False)
                headers = [str(x) for x in df.row(0)]
                df = df.slice(1)
                df.columns = headers
            return df
        except Exception:
            return pl.DataFrame()


def detectar_coluna(df, candidatos):
    cols_low = {c.lower(): c for c in df.columns}
    for cand in candidatos:
        cand = cand.lower()
        for low, original in cols_low.items():
            if cand in low:
                return original
    return None


def safe_pick(df, preferido, candidatos_extra):
    if preferido in df.columns:
        return preferido
    return detectar_coluna(df, candidatos_extra)


def limpar_pedidos(df, coluna):
    if coluna in df.columns:
        df = df.with_columns(pl.col(coluna).cast(pl.Utf8).str.strip_chars())
    return df


def converter_datetime(df: pl.DataFrame, coluna: str) -> pl.DataFrame:
    if coluna not in df.columns:
        return df

    formatos = [
        "%Y-%m-%d %H:%M:%S", "%d/%m/%Y %H:%M:%S",
        "%Y/%m/%d %H:%M", "%d/%m/%Y %H:%M",
        "%Y-%m-%d", "%d/%m/%Y", "%Y%m%d"
    ]

    for fmt in formatos:
        try:
            newdf = df.with_columns(pl.col(coluna).str.strptime(pl.Datetime, fmt, strict=False))
            if newdf[coluna].is_not_null().any():
                return newdf
        except Exception:
            continue

    return df


def ler_planilhas(pasta, nome_base):
    if not os.path.exists(pasta):
        print(f"\033[91mâŒ Pasta '{pasta}' nÃ£o encontrada.\033[0m")
        return pl.DataFrame()

    arquivos = [
        os.path.join(pasta, f)
        for f in os.listdir(pasta)
        if f.lower().endswith((".xls", ".xlsx")) and not f.startswith("~$")
    ]

    if not arquivos:
        print(f"\033[93mâš ï¸ Nenhum arquivo Excel encontrado em {nome_base}.\033[0m")
        return pl.DataFrame()

    print(f"ðŸ“‚ {len(arquivos)} arquivo(s) encontrado(s) em {nome_base}:")
    dfs = []
    for arq in arquivos:
        try:
            df_raw = pl.read_excel(arq)
            df = next(iter(df_raw.values())) if isinstance(df_raw, dict) else df_raw
            dfs.append(df)
            print(f"   âœ… {os.path.basename(arq)} ({df.height} linhas)")
        except Exception as e:
            print(f"\033[91m   âŒ Erro ao ler {os.path.basename(arq)}: {e}\033[0m")

    return pl.concat(dfs, how="diagonal_relaxed") if dfs else pl.DataFrame()


# ==========================================================
# ðŸ“¥ FunÃ§Ãµes de Leitura de Dados
# ==========================================================

def pacotes_sem_mov():
    arquivos = [f for f in os.listdir(DIR_SEMMOV) if f.endswith((".xlsx", ".xls"))]
    if not arquivos:
        return pl.DataFrame(), 0

    dfs = []
    for arq in tqdm(arquivos, desc="ðŸŸ¥ Lendo Sem MovimentaÃ§Ã£o", colour="red"):
        df = read_excel_silent(os.path.join(DIR_SEMMOV, arq))
        if not df.is_empty():
            dfs.append(df)

    if not dfs:
        return pl.DataFrame(), 0

    df = pl.concat(dfs, how="diagonal_relaxed")

    rename_map = {}
    for c in df.columns:
        if "è´£ä»»æ‰€å±žä»£ç†åŒº" in c or c == "Regional responsÃ¡vel":
            rename_map[c] = "Regional responsÃ¡vel"
        elif "è´£ä»»æœºæž„" in c or c in ("Unidade responsÃ¡vel", "Unidade responsÃ¡velè´£ä»»æœºæž„"):
            rename_map[c] = "Nome da base"
        elif "Aging" in c:
            rename_map[c] = "Aging"
        elif "JMS" in c or "è¿å•å·" in c or c == "NÃºmero de pedido JMS è¿å•å·":
            rename_map[c] = "Remessa"

    df = df.rename(rename_map)

    obrig = ["Regional responsÃ¡vel", "Nome da base", "Aging", "Remessa"]
    if not all(c in df.columns for c in obrig):
        return pl.DataFrame(), 0

    df = df.filter(
        (pl.col("Regional responsÃ¡vel").is_in(["GP", "PA"])) &
        (pl.col("Aging").is_in([
            "Exceed 5 days with no track", "Exceed 6 days with no track",
            "Exceed 7 days with no track", "Exceed 10 days with no track",
            "Exceed 14 days with no track", "Exceed 30 days with no track"
        ]))
    )

    df = _normalize_base(df)
    df = df.group_by("Nome da base").agg(pl.count("Remessa").alias("Qtd Sem Mov"))

    qtd_planilhas = len(arquivos)
    print(f"ðŸŸ¥ {qtd_planilhas} planilhas lidas, total consolidado: {df['Qtd Sem Mov'].sum()} registros")
    return df, qtd_planilhas


# ==========================================================
# ðŸ” VERSÃƒO CORRIGIDA DA FUNÃ‡ÃƒO PRINCIPAL
# ==========================================================
def coleta_expedicao():
    """
    VERSÃƒO CORRIGIDA: Lida com o novo formato de relatÃ³rio de retenÃ§Ã£o.
    """
    print("\n" + "=" * 50)
    print("ðŸ” INICIANDO LEITURA DE COLETA + EXPEDIÃ‡ÃƒO (MODO CORRIGIDO)")
    print("=" * 50 + "\n")

    arquivos = [f for f in os.listdir(DIR_COLETA) if f.endswith((".xlsx", ".xls"))]
    dfs = []

    if not arquivos:
        print("âŒ Nenhum arquivo .xlsx ou .xls encontrado na pasta de Coleta.")
        return pl.DataFrame()

    for arq in tqdm(arquivos, desc="ðŸŸ¦ Lendo Coleta + ExpediÃ§Ã£o", colour="blue"):
        df = read_excel_silent(os.path.join(DIR_COLETA, arq))
        if df.is_empty():
            continue

        # Verifica se Ã© o NOVO formato de relatÃ³rio
        if "Nome da base de entrega" in df.columns and "Qtd a entregar hÃ¡ mais de 10 dias" in df.columns:
            print(f"   âœ… Arquivo '{arq}' com novo formato detectado.")

            # Renomear colunas para o padrÃ£o do script
            rename_map = {
                "Nome da base de entrega": "Nome da base",
                "Qtd a entregar atÃ© 10 dias": "Qtd_ate_10_dias",
                "Qtd a entregar hÃ¡ mais de 10 dias": "Qtd_maior_10_dias"
            }
            df = df.rename(rename_map)

            # Normalizar nome da base
            df = _normalize_base(df)

            # O "Total Geral" serÃ¡ a soma de todas as colunas "Qtd a entregar"
            qtd_cols = [c for c in df.columns if c.startswith("Qtd a entregar")]
            df = df.with_columns(
                pl.sum(qtd_cols).alias("Total Geral")
            )

            # A "Qtd Entregue com assinatura" nÃ£o existe neste formato. Preenchemos com 0.
            df = df.with_columns(
                pl.lit(0).alias("Quantidade entregue com assinatura")
            )

            cols_sel = ["Nome da base", "Total Geral", "Quantidade entregue com assinatura", "Qtd_ate_10_dias",
                        "Qtd_maior_10_dias"]
            dfs.append(df.select(cols_sel))
        else:
            # Se nÃ£o for o novo formato, verifica se Ã© o antigo (caso tenha arquivos misturados)
            obrig_antigo = ["Nome da base", "Quantidade coletada", "Quantidade com saÃ­da para entrega",
                            "Quantidade entregue com assinatura"]
            if all(c in df.columns for c in obrig_antigo):
                print(f"   âœ… Arquivo '{arq}' com formato antigo detectado.")
                df = _normalize_base(df).with_columns([
                    to_float("Quantidade coletada"),
                    to_float("Quantidade com saÃ­da para entrega"),
                    to_float("Quantidade entregue com assinatura"),
                    (pl.col("Quantidade coletada") + pl.col("Quantidade com saÃ­da para entrega")).alias("Total Geral")
                ])
                cols_sel = ["Nome da base", "Total Geral", "Quantidade entregue com assinatura"]
                dfs.append(df.select(cols_sel))
            else:
                print(f"   âš ï¸ Arquivo '{arq}' com formato nÃ£o reconhecido. Ignorando.")

    if not dfs:
        print("\nâŒ Nenhum arquivo vÃ¡lido foi processado.")
        return pl.DataFrame()

    df = pl.concat(dfs, how="diagonal_relaxed")

    aggs = [
        pl.sum("Total Geral").alias("Total Coleta+Entrega"),
        pl.sum("Quantidade entregue com assinatura").alias("Qtd Entregue Assinatura")
    ]

    if "Qtd_ate_10_dias" in df.columns:
        aggs.append(pl.sum("Qtd_ate_10_dias").alias("Qtd_ate_10_dias"))

    if "Qtd_maior_10_dias" in df.columns:
        aggs.append(pl.sum("Qtd_maior_10_dias").alias("Qtd_maior_10_dias"))

    df_agregado = df.group_by("Nome da base").agg(aggs)
    return _normalize_base(df_agregado)


def ressarcimento_por_pacote(df_coleta):
    arquivos = [f for f in os.listdir(DIR_RESS) if f.endswith((".xlsx", ".xls"))]
    if not arquivos:
        return pl.DataFrame()

    df = read_excel_silent(os.path.join(DIR_RESS, sorted(arquivos)[-1]))
    if df.is_empty() or "Regional responsÃ¡vel" not in df.columns:
        return pl.DataFrame()

    df = df.filter(pl.col("Regional responsÃ¡vel").str.to_uppercase() == "GP")
    df = df.with_columns(to_float("Valor a pagar (yuan)").alias("Custo total (R$)"))
    df = df.group_by("Base responsÃ¡vel").agg(pl.sum("Custo total (R$)").alias("Custo total (R$)"))
    df = df.rename({"Base responsÃ¡vel": "Nome da base"})
    df = _normalize_base(df)

    if not df_coleta.is_empty():
        df = _safe_full_join(df, df_coleta.select(["Nome da base", "Qtd Entregue Assinatura"]))

    df = df.fill_null(0).with_columns([
        (pl.when(pl.col("Qtd Entregue Assinatura") > 0)
         .then(pl.col("Custo total (R$)") / pl.col("Qtd Entregue Assinatura"))
         .otherwise(0)).alias("Ressarcimento p/pct (R$)")
    ])

    return df.select(["Nome da base", "Custo total (R$)", "Ressarcimento p/pct (R$)"])


def taxa_t0():
    """
    Taxa T-0 baseada no motor v2.8.
    """
    arquivos = [
        os.path.join(DIR_T0, f)
        for f in os.listdir(DIR_T0)
        if f.lower().endswith((".xls", ".xlsx", ".csv")) and not f.startswith("~$")
    ]

    if not arquivos:
        print("âš ï¸ Nenhum arquivo T0 encontrado.")
        return pl.DataFrame({"Nome da base": [], "SLA (%)": []})

    with ThreadPoolExecutor(max_workers=min(16, len(arquivos))) as ex:
        dfs = list(ex.map(read_excel_silent, arquivos))

    dfs = [df for df in dfs if not df.is_empty()]
    if not dfs:
        print("âš ï¸ Falha ao ler arquivos T0.")
        return pl.DataFrame({"Nome da base": [], "SLA (%)": []})

    df = pl.concat(dfs, how="vertical_relaxed")
    df = df.rename({c: c.strip().upper() for c in df.columns})

    possiveis_base = ["BASE DE ENTREGA", "NOME DA BASE", "BASE", "UNIDADE", "UNIDADE RESPONSÃVEL"]
    col_base = next((c for c in df.columns if c.upper() in [p.upper() for p in possiveis_base]), None)
    if not col_base:
        raise KeyError(f"âŒ Nenhuma coluna equivalente a Base encontrada.\nColunas: {df.columns}")

    possiveis_prazo = ["ENTREGUE NO PRAZO?", "ENTREGUE NO PRAZOï¼Ÿ", "ENTREGUE NO PRAZO"]
    col_prazo = next((c for c in df.columns if c.upper() in [p.upper() for p in possiveis_prazo]), None)
    if not col_prazo:
        raise KeyError(f"âŒ Nenhuma coluna ENTREGUE NO PRAZO encontrada.\nColunas: {df.columns}")

    df = df.with_columns(
        pl.when(pl.col(col_prazo).cast(pl.Utf8).str.to_uppercase() == "Y")
        .then(1).otherwise(0).alias("_ENTREGUE_PRAZO")
    )

    df = df.with_columns(
        pl.col(col_base).map_elements(_normalize_strong).alias("Nome da base")
    )

    return (
        df.group_by("Nome da base")
        .agg((pl.col("_ENTREGUE_PRAZO").sum() / pl.len()).alias("SLA (%)"))
        .select(["Nome da base", "SLA (%)"])
    )


# ==========================================================
# ðŸš€ RETIDOS (MOTOR ANTIGO) + % REAL COM QTD >10 DIAS
# ==========================================================

def analisar_retidos_motor_antigo():
    """
    Motor antigo:
    - filtra >6 dias
    - remove devoluÃ§Ã£o, problemÃ¡ticos, custÃ³dia
    - retorna Qtd Retidos por base
    """
    print(
        "\n==============================\nðŸš€ INICIANDO ANÃLISE DE RETIDOS (MOTOR ANTIGO)\n==============================")

    removidos_cluster = removidos_dev = removidos_prob = removidos_cust = 0

    df_ret = ler_planilhas(DIR_RETIDOS, "Retidos")
    if df_ret.is_empty():
        print("âŒ Nenhum dado em Retidos.")
        return pl.DataFrame({"Nome da base": [], "Qtd Retidos": []})

    # 1) CLUSTER > 6 DIAS
    col_cluster = safe_pick(df_ret, "Dias Retidos æ»žç•™æ—¥", ["æ»žç•™", "dias", "retidos"])
    if col_cluster and col_cluster in df_ret.columns:
        total_antes = df_ret.height
        df_ret = df_ret.with_columns(pl.col(col_cluster).cast(pl.Utf8, strict=False))

        def extrair_maior_dia(texto: str) -> int:
            if texto is None:
                return 999
            nums = re.findall(r"\d+", str(texto))
            return max(int(n) for n in nums) if nums else 999

        df_ret = df_ret.with_columns(
            pl.col(col_cluster).map_elements(extrair_maior_dia, return_dtype=pl.Int64).alias("dias_max")
        )
        df_ret = df_ret.filter(pl.col("dias_max") > 6).drop("dias_max")
        removidos_cluster = total_antes - df_ret.height
        print(f"\033[95mðŸ§¹ Removidos (0â€“6 dias): {removidos_cluster} | Mantidos: {df_ret.height}\033[0m")

    # 2) COLUNAS PRINCIPAIS
    col_pedido_ret = safe_pick(df_ret, "NÃºmero do Pedido JMS è¿å•å·", ["pedido", "è¿å•", "jms"])
    col_data_ret = safe_pick(df_ret, "Data da AtualizaÃ§Ã£o æ›´æ–°æ—¥æœŸ", ["data", "atualiza", "æ›´æ–°"])
    col_regional = safe_pick(df_ret, "Regional åŒºåŸŸ", ["regional", "åŒºåŸŸ"])
    col_base_entrega = safe_pick(df_ret, "Base de Entrega æ´¾ä»¶ç½‘ç‚¹", ["base", "ç½‘ç‚¹", "æ´¾ä»¶"])

    cols = [c for c in [col_pedido_ret, col_data_ret, col_regional, col_base_entrega] if c]
    df_ret = df_ret.select(cols).rename({
        col_pedido_ret: "PEDIDO",
        col_data_ret: "DATA_ATUALIZACAO",
        col_regional: "REGIONAL" if col_regional else None,
        col_base_entrega: "BASE_ENTREGA" if col_base_entrega else None
    })

    df_ret = limpar_pedidos(df_ret, "PEDIDO")
    df_ret = converter_datetime(df_ret, "DATA_ATUALIZACAO")

    if "REGIONAL" in df_ret.columns:
        df_ret = df_ret.filter(pl.col("REGIONAL").is_in(REGIONAIS_DESEJADAS))

    total_inicial = df_ret.height
    print(f"\033[92mðŸŸ¢ Retidos filtrados ({', '.join(REGIONAIS_DESEJADAS)}): {total_inicial}\033[0m")

    # 3) DEVOLUÃ‡ÃƒO
    df_dev = ler_planilhas(DIR_DEVOLUCAO, "DevoluÃ§Ã£o")
    if not df_dev.is_empty():
        col_pedido_dev = safe_pick(df_dev, "NÃºmero de pedido JMS", ["pedido", "jms"])
        col_data_dev = safe_pick(df_dev, "Tempo de solicitaÃ§Ã£o", ["solicit", "tempo", "data"])

        if col_pedido_dev and col_data_dev:
            df_dev = (
                df_dev.select([col_pedido_dev, col_data_dev])
                .rename({col_pedido_dev: "PEDIDO_DEV", col_data_dev: "DATA_DEV"})
                .pipe(limpar_pedidos, "PEDIDO_DEV")
                .pipe(converter_datetime, "DATA_DEV")
                .group_by("PEDIDO_DEV")
                .agg(pl.col("DATA_DEV").min())
            )

            dfj = df_ret.join(df_dev, left_on="PEDIDO", right_on="PEDIDO_DEV", how="left")

            df_rem = dfj.filter(
                (pl.col("DATA_DEV") > pl.col("DATA_ATUALIZACAO")) &
                pl.col("DATA_DEV").is_not_null()
            )

            removidos_dev = df_rem.height
            df_ret = dfj.filter(~pl.col("PEDIDO").is_in(df_rem["PEDIDO"])).drop(["PEDIDO_DEV", "DATA_DEV"],
                                                                                strict=False)
            print(f"\033[93mðŸŸ¡ DevoluÃ§Ã£o â†’ Removidos: {removidos_dev} | Mantidos: {df_ret.height}\033[0m")

    # 4) PROBLEMÃTICOS
    df_prob = ler_planilhas(DIR_PROBLEMATICOS, "ProblemÃ¡ticos")
    if not df_prob.is_empty():
        col_pedido_prob = safe_pick(df_prob, "NÃºmero de pedido JMS", ["pedido", "jms", "è¿å•"])
        col_data_prob = safe_pick(df_prob, "data de registro", ["registro", "data", "å¼‚å¸¸"])

        if col_pedido_prob and col_data_prob:
            df_prob = (
                df_prob.select([col_pedido_prob, col_data_prob])
                .rename({col_pedido_prob: "PEDIDO_PROB", col_data_prob: "DATA_PROB"})
                .pipe(limpar_pedidos, "PEDIDO_PROB")
                .pipe(converter_datetime, "DATA_PROB")
                .group_by("PEDIDO_PROB")
                .agg(pl.col("DATA_PROB").min())
            )

            dfj = df_ret.join(df_prob, left_on="PEDIDO", right_on="PEDIDO_PROB", how="left")

            df_rem = dfj.filter(
                (pl.col("DATA_PROB") >= pl.col("DATA_ATUALIZACAO")) &
                pl.col("DATA_PROB").is_not_null()
            )

            removidos_prob = df_rem.height
            df_ret = dfj.filter(~pl.col("PEDIDO").is_in(df_rem["PEDIDO"])).drop(["PEDIDO_PROB", "DATA_PROB"],
                                                                                strict=False)
            print(f"\033[38;5;208mðŸŸ  ProblemÃ¡ticos â†’ Removidos: {removidos_prob} | Mantidos: {df_ret.height}\033[0m")
    # 5) CUSTÃ“DIA
    df_cust = ler_planilhas(DIR_CUSTODIA, "CustÃ³dia")
    if not df_cust.is_empty():
        col_pedido_c = safe_pick(df_cust, "NÃºmero de pedido JMS", ["pedido", "jms"])
        col_data_c = safe_pick(df_cust, "data de registro", ["registro", "data"])

        if col_pedido_c and col_data_c:
            df_cust = (
                df_cust.select([col_pedido_c, col_data_c])
                .rename({col_pedido_c: "PEDIDO_CUST", col_data_c: "DATA_CUST"})
                .pipe(limpar_pedidos, "PEDIDO_CUST")
                .pipe(converter_datetime, "DATA_CUST")
                .group_by("PEDIDO_CUST")
                .agg(pl.col("DATA_CUST").min().alias("DATA_CUST"))
                .with_columns((pl.col("DATA_CUST") + pl.duration(days=PRAZO_CUSTODIA_DIAS)).alias("PRAZO_LIMITE"))
            )

            dfj = df_ret.join(df_cust, left_on="PEDIDO", right_on="PEDIDO_CUST", how="left")

            dfj = dfj.with_columns(
                pl.when(
                    (pl.col("DATA_ATUALIZACAO") <= pl.col("PRAZO_LIMITE")) &
                    pl.col("PRAZO_LIMITE").is_not_null()
                ).then(pl.lit("Dentro")).otherwise(pl.lit("Fora")).alias("STATUS_CUSTODIA")
            )

            df_rem = dfj.filter(pl.col("STATUS_CUSTODIA") == "Dentro")
            removidos_cust = df_rem.height

            df_ret = dfj.filter(pl.col("STATUS_CUSTODIA") == "Fora").drop(
                ["PEDIDO_CUST", "DATA_CUST", "PRAZO_LIMITE", "STATUS_CUSTODIA"],
                strict=False
            )

            print(f"\033[94mðŸ”µ CustÃ³dia â†’ Removidos: {removidos_cust} | Mantidos: {df_ret.height}\033[0m")

    # 6) AGREGAR POR BASE
    if "BASE_ENTREGA" in df_ret.columns and df_ret.height > 0:
        df_retidos_base = (
            df_ret.with_columns(
                pl.col("BASE_ENTREGA").map_elements(_normalize_strong).alias("Nome da base")
            )
            .group_by("Nome da base")
            .agg(pl.count().alias("Qtd Retidos"))
        )
    else:
        df_retidos_base = pl.DataFrame({"Nome da base": [], "Qtd Retidos": []})

    # Detalhado opcional
    if GERAR_DETALHADO_RETIDOS and df_ret.height > 0:
        out_final = os.path.join(DIR_OUT, f"Resultado_Detalhado_Retidos_{datetime.now():%Y%m%d_%H%M%S}.xlsx")
        df_ret.write_excel(out_final)
        print(f"\nðŸ“Š Resultado detalhado exportado: {out_final}")

    return df_retidos_base


def calcular_retidos_reais(df_retidos_motor: pl.DataFrame, df_coleta: pl.DataFrame) -> pl.DataFrame:
    """
    % Retidos Real = Qtd Retidos (motor antigo) / Qtd_maior_10_dias (coleta+expediÃ§Ã£o)
    CORREÃ‡ÃƒO: O denominador agora Ã© a quantidade de pacotes com mais de 10 dias.

    Retorna:
        Nome da base | Qtd Retidos | Qtd_maior_10_dias | % Retidos Real
    """
    if df_retidos_motor.is_empty():
        return pl.DataFrame({"Nome da base": [], "Qtd Retidos": [], "Qtd_maior_10_dias": [], "% Retidos Real": []})

    df_retidos_motor = df_retidos_motor.with_columns(
        pl.col("Nome da base").map_elements(_normalize_strong, return_dtype=pl.Utf8)
    )

    # CORREÃ‡ÃƒO: Usar Qtd_maior_10_dias como denominador
    if df_coleta.is_empty() or "Qtd_maior_10_dias" not in df_coleta.columns:
        return df_retidos_motor.with_columns(
            pl.lit(0).alias("Qtd_maior_10_dias"),
            pl.lit(0).alias("% Retidos Real")
        )

    df_coleta_maior_10 = df_coleta.select(["Nome da base", "Qtd_maior_10_dias"]).with_columns(
        pl.col("Nome da base").map_elements(_normalize_strong, return_dtype=pl.Utf8)
    )

    df = df_retidos_motor.join(df_coleta_maior_10, on="Nome da base", how="left").fill_null(0)

    df = df.with_columns(
        pl.when(pl.col("Qtd_maior_10_dias") > 0)
        .then((pl.col("Qtd Retidos") / pl.col("Qtd_maior_10_dias")).round(4))
        .otherwise(0)
        .alias("% Retidos Real")
    )

    return df


# ==========================================================
# ðŸ“˜ COORDENADORES â€” pasta nova, sÃ³ Base + Coordenador
# ==========================================================

def carregar_coordenadores():
    """
    LÃª Base_Dados_Geral.xlsx dentro de DIR_COORDENADOR.
    MantÃ©m somente Nome da base + Coordenador.
    """
    path_coord = os.path.join(DIR_COORDENADOR, "Base_Dados_Geral.xlsx")
    df_coord = read_excel_silent(path_coord)

    if df_coord.is_empty():
        print("âš ï¸ Planilha Base_Dados_Geral.xlsx nÃ£o encontrada ou vazia.")
        return pl.DataFrame({"Nome da base": [], "Coordenador": []})

    col_base = None
    for possible in ["Base", "Nome da base", "Unidade", "Unidade responsÃ¡vel"]:
        if possible in df_coord.columns:
            col_base = possible
            break

    if col_base is None:
        raise SystemExit("âŒ Nenhuma coluna identificada como 'Base' ou equivalente em Base_Dados_Geral.xlsx")

    df_coord = df_coord.rename({
        col_base: "Nome da base",
        "Coordenador": "Coordenador"
    })

    df_coord = df_coord.select([c for c in ["Nome da base", "Coordenador"] if c in df_coord.columns])
    df_coord = _normalize_base(df_coord)

    print(f"âœ… {df_coord.height} coordenadores carregados e normalizados.")
    return df_coord


# ==========================================================
# ðŸ§® ConsolidaÃ§Ã£o de Dados
# ==========================================================

def consolidar():
    dias = calendar.monthrange(datetime.now().year, datetime.now().month)[1]

    df_coord = carregar_coordenadores()

    df_coleta = coleta_expedicao()
    df_t0 = taxa_t0()

    # RETIDOS: motor antigo + % real usando Qtd_maior_10_dias da coleta
    df_retidos_motor = analisar_retidos_motor_antigo()
    df_retidos = calcular_retidos_reais(df_retidos_motor, df_coleta)

    df_ress = ressarcimento_por_pacote(df_coleta)
    df_sem, _ = pacotes_sem_mov()

    df_final = _safe_full_join(df_t0, df_retidos)
    df_final = _safe_full_join(df_final, df_ress)
    df_final = _safe_full_join(df_final, df_sem)
    df_final = _safe_full_join(df_final, df_coleta)
    df_final = _safe_full_join(df_coord, df_final)

    # Taxa Sem Mov
    if "Total Coleta+Entrega" in df_final.columns:
        df_final = df_final.fill_null(0).with_columns([
            (pl.when(pl.col("Total Coleta+Entrega") > 0)
             .then(pl.col("Qtd Sem Mov") / dias / pl.col("Total Coleta+Entrega"))
             .otherwise(0)).alias("Taxa Sem Mov.")
        ])
    else:
        df_final = df_final.with_columns(pl.lit(0).alias("Taxa Sem Mov."))

    # ORDEM CORRIGIDA: Adiciona as novas colunas
    ordered = [
        "Nome da base", "Coordenador",
        "SLA (%)",
        "Qtd Retidos", "Qtd_maior_10_dias", "% Retidos Real",
        "Ressarcimento p/pct (R$)", "Custo total (R$)",
        "Qtd Sem Mov", "Taxa Sem Mov.",
        "Total Coleta+Entrega", "Qtd_ate_10_dias"  # Coluna extra no final
    ]

    # garantir que todas colunas existam
    for c in ordered:
        if c not in df_final.columns:
            df_final = df_final.with_columns(pl.lit(None).alias(c))

    # Ajuste de tipos
    text_cols = [c for c in df_final.columns if df_final.schema[c] == pl.Utf8]
    numeric_cols = [c for c in df_final.columns if df_final.schema[c] != pl.Utf8]

    if text_cols:
        df_final = df_final.with_columns([pl.col(c).fill_null("") for c in text_cols])

    if numeric_cols:
        for c in numeric_cols:
            df_final = df_final.with_columns(pl.col(c).fill_null(0).fill_nan(0))

    return df_final.select(ordered).unique(subset=["Nome da base"], keep="first")


# ==========================================================
# ðŸ’¾ Exportar RelatÃ³rio Formatado
# ==========================================================

def main():
    diagnosticar_normalizacao()

    df = consolidar()
    if df.is_empty():
        print("âš ï¸ Nenhum dado consolidado.")
        return

    out = os.path.join(DIR_OUT, f"Resumo_Politica_Bonificacao_{datetime.now():%Y%m%d_%H%M%S}.xlsx")

    df_pd = df.to_pandas()
    with pd.ExcelWriter(out, engine="xlsxwriter") as writer:
        startrow = 6
        df_pd.to_excel(writer, sheet_name="BonificaÃ§Ã£o", startrow=startrow, startcol=0, header=True, index=False)

        wb, ws = writer.book, writer.sheets["BonificaÃ§Ã£o"]

        red = wb.add_format({
            "bold": True, "font_color": "white", "align": "center",
            "valign": "vcenter", "bg_color": "#C00000", "border": 1
        })
        gray = wb.add_format({
            "bold": True, "font_color": "white", "align": "center",
            "valign": "vcenter", "bg_color": "#595959", "border": 1
        })
        center = wb.add_format({"align": "center", "valign": "vcenter"})
        fmt_percent_2 = wb.add_format({"num_format": "0.00%", "align": "center"})
        fmt_money = wb.add_format({"num_format": '"R$"#,##0.00', "align": "center"})
        fmt_int = wb.add_format({"num_format": "0", "align": "center"})

        # Ajuste para 13 colunas
        ws.merge_range("A1:M1", "RESULTADOS DE INDICADORES â€” POLÃTICA DE BONIFICAÃ‡ÃƒO", red)
        ws.merge_range("A2:M2", f"Data de atualizaÃ§Ã£o: {datetime.now():%d/%m/%Y}", gray)

        # CabeÃ§alhos corrigidos e reordenados
        headers = [
            ("A6", "Nome da base"),
            ("B6", "Coordenador"),
            ("C6", "SLA (%)"),
            ("D6", "Qtd Retidos"),
            ("E6", "Qtd >10 dias (Denominador)"),
            ("F6", "% Retidos Real"),
            ("G6", "Ressarcimento p/pct (R$)"),
            ("H6", "Custo total (R$)"),
            ("I6", "Qtd Sem Mov"),
            ("J6", "Taxa Sem Mov."),
            ("K6", "Total Coleta+Entrega"),
            ("L6", "Qtd atÃ© 10 dias")
        ]

        for c, t in headers:
            ws.write(c, t, red)

        # FormataÃ§Ã£o das colunas
        ws.set_column("A:B", 22, center)
        ws.set_column("C:C", 12, fmt_percent_2)
        ws.set_column("D:D", 14, fmt_int)
        ws.set_column("E:E", 18, fmt_int)
        ws.set_column("F:F", 12, fmt_percent_2)
        ws.set_column("G:H", 16, fmt_money)
        ws.set_column("I:I", 14, fmt_int)
        ws.set_column("J:J", 14, fmt_percent_2)
        ws.set_column("K:K", 16, fmt_int)
        ws.set_column("L:L", 16, fmt_int)

        ws.freeze_panes(7, 0)

    print(f"âœ… RelatÃ³rio final gerado com sucesso!\nðŸ“‚ {out}")


# ==========================================================
# ExecuÃ§Ã£o do Script
# ==========================================================

if __name__ == "__main__":
    main()