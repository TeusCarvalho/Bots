# -*- coding: utf-8 -*-

import os
import math
import polars as pl
import pandas as pd
from tqdm import tqdm

# ======================================================
# ‚öôÔ∏è CONFIGURA√á√ïES
# ======================================================

PASTA_ENTRADA = r"C:\Users\J&T-099\OneDrive - Speed Rabbit Express Ltda (1)\√Årea de Trabalho\Sem Movimenta√ß√£o"
ARQUIVO_SAIDA = os.path.join(PASTA_ENTRADA, "Bases_Unificadas.xlsx")
LIMITE_EXCEL = 1_048_000  # limite seguro por aba (~1 milh√£o de linhas)

# ======================================================
# üß† FUN√á√ïES AUXILIARES
# ======================================================

def listar_planilhas(pasta: str):
    """Lista arquivos Excel v√°lidos, ignorando tempor√°rios (~$) e sa√≠das."""
    arquivos = []
    for f in os.listdir(pasta):
        nome_arquivo = f.lower()
        if (
            nome_arquivo.endswith(".xlsx")
            and not nome_arquivo.startswith("~$")
            and not nome_arquivo.startswith("bases_")
            and f.lower() != os.path.basename(ARQUIVO_SAIDA).lower()
        ):
            arquivos.append(os.path.join(pasta, f))
    return arquivos


def harmonizar_sinonimos(df: pl.DataFrame) -> pl.DataFrame:
    """
    Une colunas que s√£o a mesma informa√ß√£o com nomes diferentes.
    Regra: cria/atualiza a coluna can√¥nica com COALESCE(candidatas...) e remove as candidatas extras.
    """

    # ‚úÖ Ajuste aqui conforme voc√™ encontrar novos casos
    SINONIMOS = {
        "Remessa": ["Remessa", "N√∫mero de pedido JMS ËøêÂçïÂè∑"],
    }

    for canonica, candidatas in SINONIMOS.items():
        existentes = [c for c in candidatas if c in df.columns]
        if not existentes:
            continue

        if canonica in df.columns:
            # canonica j√° existe: coalesce(canonica, outras...)
            cols = [pl.col(canonica)] + [pl.col(c) for c in existentes if c != canonica]
            df = df.with_columns(pl.coalesce(cols).alias(canonica))
        else:
            # canonica n√£o existe: cria a partir das candidatas
            cols = [pl.col(c) for c in existentes]
            df = df.with_columns(pl.coalesce(cols).alias(canonica))

        # remove candidatas extras (mant√©m apenas a can√¥nica)
        drop_cols = [c for c in existentes if c != canonica]
        if drop_cols:
            df = df.drop(drop_cols)

    return df
# ======================================================
# üöÄ EXECU√á√ÉO PRINCIPAL
# ======================================================

def main():
    print(f"üîç Procurando planilhas em:\n{PASTA_ENTRADA}\n")
    arquivos = listar_planilhas(PASTA_ENTRADA)

    if not arquivos:
        print("‚ö†Ô∏è Nenhum arquivo encontrado.")
        return

    print(f"üìÅ {len(arquivos)} arquivo(s) encontrado(s):")
    for a in arquivos:
        print(f"  ‚Ä¢ {os.path.basename(a)}")
    print("")

    dfs_lazy = []
    resumo_arquivos = []

    for arquivo in tqdm(arquivos, desc="üìñ Lendo planilhas", ncols=80):
        nome = os.path.basename(arquivo)
        try:
            # L√™ UMA vez (antes voc√™ lia 2x por arquivo)
            df_eager = pl.read_excel(arquivo)

            # Harmoniza nomes equivalentes (ex.: ËøêÂçïÂè∑ -> Remessa)
            df_eager = harmonizar_sinonimos(df_eager)

            # Adiciona coluna de origem
            df_eager = df_eager.with_columns(pl.lit(nome).alias("Arquivo_Origem"))

            # Lazy para permitir concat com otimiza√ß√µes
            dfs_lazy.append(df_eager.lazy())

            resumo_arquivos.append({"Arquivo": nome, "Linhas": df_eager.height})

        except Exception as e:
            print(f"‚ùå Erro ao ler '{nome}': {e}")

    if not dfs_lazy:
        print("‚ö†Ô∏è Nenhum dado carregado.")
        return

    print("üß© Combinando tudo com Polars (concat seguro)...")

    # ‚úÖ Importante:
    # how="diagonal_relaxed" une colunas diferentes e preenche faltantes com null,
    # al√©m de tentar compatibilizar tipos quando necess√°rio.
    df_total = pl.concat(dfs_lazy, how="diagonal_relaxed").collect()

    total_linhas, total_colunas = df_total.shape
    print(f"\nüìä Total consolidado: {total_linhas:,} linhas e {total_colunas} colunas\n".replace(",", "."))
    # Divide em partes para respeitar limite do Excel
    partes = math.ceil(total_linhas / LIMITE_EXCEL)
    partes_geradas = []

    with pd.ExcelWriter(ARQUIVO_SAIDA, engine="openpyxl") as writer:
        for i in tqdm(range(partes), desc="‚úÇÔ∏è Criando abas", ncols=80):
            inicio = i * LIMITE_EXCEL
            if inicio >= total_linhas:
                break

            qtd = min(LIMITE_EXCEL, total_linhas - inicio)

            # ‚úÖ Converte apenas o peda√ßo necess√°rio para Pandas (melhor RAM)
            df_parte_pd = df_total.slice(inicio, qtd).to_pandas()

            if df_parte_pd.empty:
                continue

            aba_nome = f"Parte_{i+1}"
            df_parte_pd.to_excel(writer, sheet_name=aba_nome, index=False)

            partes_geradas.append({"Aba": aba_nome, "Linhas": len(df_parte_pd)})
            print(f"‚úÖ {aba_nome} criada ({len(df_parte_pd):,} linhas)".replace(",", "."))

        # Abas de resumo
        df_resumo = pd.DataFrame(partes_geradas)
        df_arquivos = pd.DataFrame(resumo_arquivos)
        df_resumo.to_excel(writer, sheet_name="Resumo_Geral", index=False)
        df_arquivos.to_excel(writer, sheet_name="Resumo_Arquivos", index=False)

    print("\n‚úÖ Consolida√ß√£o conclu√≠da com sucesso!")
    print(f"üìÅ Arquivo final salvo em:\n{ARQUIVO_SAIDA}")
    print(f"üìä Total: {total_linhas:,} linhas em {len(partes_geradas)} aba(s)\n".replace(",", "."))


# ======================================================
# ‚ñ∂Ô∏è EXECUTAR
# ======================================================
if __name__ == "__main__":
    main()
