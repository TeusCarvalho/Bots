# -*- coding: utf-8 -*-

import requests
import json
from datetime import datetime
import time
import os
import pandas as pd
from typing import Dict, Any, Optional

# ==============================================================================
# CONFIGURA√á√ïES GERAIS
# ==============================================================================

COORDENADOR_WEBHOOKS = {
    "Jo√£o Melo": "https://open.feishu.cn/open-apis/bot/v2/hook/1d9bbacf-79ed-4eb3-8046-26d7480893c3",
    "Johas Vieira": "https://open.feishu.cn/open-apis/bot/v2/hook/5c2bb460-1971-4770-9b37-98b6e4ba3cd9",
    "Anderson Matheus": "https://open.feishu.cn/open-apis/bot/v2/hook/ac4a5800-44b5-45d5-b0d2-f4d88a677967",
    "Marcelo Medina": "https://open.feishu.cn/open-apis/bot/v2/hook/20a61c63-6db7-4e83-9e44-ae6b545495cc",
    "Od√°ria Fereira": "https://open.feishu.cn/open-apis/bot/v2/hook/914ce9f9-35ab-4869-860f-d2bef7d933fb",
    "Rodrigo Castro": "https://open.feishu.cn/open-apis/bot/v2/hook/16414836-5020-49bd-b3d3-ded4f34878ab",
    "Orlean Nascimento": "https://open.feishu.cn/open-apis/bot/v2/hook/62cd648c-ecd5-406a-903d-b596944c1919",
    "Jose Marlon": "https://open.feishu.cn/open-apis/bot/v2/hook/62518b67-f897-4341-98e6-2db87f4fdee2",
    "Emerson Silva": "https://open.feishu.cn/open-apis/bot/v2/hook/e502bc10-3cb3-4b46-872e-eb73ef1c5ee0",
    "Marcos Caique": "https://open.feishu.cn/open-apis/bot/v2/hook/db18d309-8f26-41b5-b911-1a9f27449c83"
}

REPORTS_FOLDER_PATH = r"C:\Users\J&T-099\OneDrive - Speed Rabbit Express Ltda\Jt - Relat√≥rios"
ARQUIVO_MORTO_FOLDER = os.path.join(REPORTS_FOLDER_PATH, "Arquivo Morto")

LINK_RELATORIO = "https://jtexpressdf-my.sharepoint.com/:f:/g/personal/matheus_carvalho_jtexpressdf_onmicrosoft_com/Ek3KdqMIdX5EodE-3JwCQnsBAMiJ574BsxAR--oYBNN0-g?e=dfqBzT"


# ==============================================================================
# FUN√á√ïES DE APOIO
# ==============================================================================

def format_currency_brl(value: float) -> str:
    return f"R$ {value:,.2f}".replace(",", "X").replace(".", ",").replace("X", ".")


def carregar_ultimo_arquivo_morto() -> Optional[pd.DataFrame]:
    """Procura no Arquivo Morto o √∫ltimo arquivo que contenha '5+ dias' no nome"""
    if not os.path.exists(ARQUIVO_MORTO_FOLDER):
        print("‚ö†Ô∏è Pasta Arquivo Morto n√£o encontrada.")
        return None

    arquivos = [
        f for f in os.listdir(ARQUIVO_MORTO_FOLDER)
        if f.lower().endswith((".xlsx", ".xls")) and "5+ dias" in f
    ]
    if not arquivos:
        print("‚ö†Ô∏è Nenhum arquivo compat√≠vel em Arquivo Morto contendo '5+ dias'.")
        return None

    arquivos.sort(key=lambda x: os.path.getmtime(os.path.join(ARQUIVO_MORTO_FOLDER, x)), reverse=True)
    ultimo_arquivo = os.path.join(ARQUIVO_MORTO_FOLDER, arquivos[0])

    print(f"üìÇ Usando {ultimo_arquivo} como relat√≥rio anterior.")
    try:
        return pd.read_excel(ultimo_arquivo)
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao ler {ultimo_arquivo}: {e}")
        return None


# ==============================================================================
# PREPARA√á√ÉO DO RELAT√ìRIO
# ==============================================================================

def prepare_report_data(df_current: pd.DataFrame, df_old: Optional[pd.DataFrame], report_title: str) -> Dict[str, Any]:
    total_current = df_current["Remessa"].nunique() if "Remessa" in df_current.columns else len(df_current)
    current_fines = df_current["Multa (R$)"].sum() if "Multa (R$)" in df_current.columns else 0

    var_text, var_f_text = "N/A", "N/A"

    if df_old is not None and not df_old.empty:
        total_old = df_old["Remessa"].nunique() if "Remessa" in df_old.columns else len(df_old)
        difference = total_current - total_old
        if difference < 0:
            var_text = f"üìâ Diminuiu {abs(difference)} pedidos"
        elif difference > 0:
            var_text = f"üìà Aumentou {difference} pedidos"
        else:
            var_text = "‚ûñ Sem altera√ß√£o"

        if "Multa (R$)" in df_old.columns:
            old_fines = df_old["Multa (R$)"].sum()
            fines_diff = current_fines - old_fines
            if fines_diff < 0:
                var_f_text = f"üìâ Diminuiu {format_currency_brl(abs(fines_diff))}"
            elif fines_diff > 0:
                var_f_text = f"üìà Aumentou {format_currency_brl(fines_diff)}"
            else:
                var_f_text = "‚ûñ Sem altera√ß√£o"

    # ======================================================================
    # TOP BASES (piores atuais e melhores redu√ß√µes)
    # ======================================================================
    metrics_text = ""

    if "Unidade respons√°vel" in df_current.columns and "Remessa" in df_current.columns:
        # Contagem atual por base
        base_counts = (
            df_current.groupby("Unidade respons√°vel")["Remessa"]
            .nunique()
            .sort_values(ascending=False)
        )

        # üî¥ 3 piores (maiores quantidades atuais)
        worst_bases = base_counts.head(3)
        metrics_text += "**üî¥ 3 Piores Bases (maior n¬∫ de pedidos):**\n"
        for unit, count in worst_bases.items():
            metrics_text += f"- üî¥ **{unit}**: {count} pedidos\n"

        metrics_text += "\n"

        # üü¢ 3 melhores (maiores redu√ß√µes em rela√ß√£o ao relat√≥rio anterior)
        if df_old is not None and "Unidade respons√°vel" in df_old.columns:
            old_counts = df_old.groupby("Unidade respons√°vel")["Remessa"].nunique()

            # Diferen√ßa: pedidos antigos - atuais (positivo = redu√ß√£o)
            diffs = (old_counts - base_counts).dropna().sort_values(ascending=False)

            best_reductions = diffs.head(3)
            metrics_text += "**üü¢ 3 Melhores Redu√ß√µes:**\n"
            for unit, reduction in best_reductions.items():
                atual = base_counts.get(unit, 0)
                anterior = old_counts.get(unit, 0)
                metrics_text += f"- üü¢ **{unit}**: reduziu {int(reduction)} (de {anterior} ‚Üí {atual})\n"

    return {
        "title": f"{report_title}",
        "metrics_text": metrics_text,
        "observation": "Resumo autom√°tico.",
        "total_pacotes": total_current,
        "variacao_pacotes": var_text,
        "multa_atual": format_currency_brl(current_fines),
        "variacao_multa": var_f_text,
    }


# ==============================================================================
# FORMATA√á√ÉO DO CARD PARA FEISHU
# ==============================================================================

def create_feishu_card_payload(report_data: Dict[str, Any]) -> Dict[str, Any]:
    elements = [
        {"tag": "div", "fields": [
            {"is_short": True, "text": {"tag": "lark_md",
                "content": (
                    f"**Data de Gera√ß√£o:**\n{report_data.get('date', 'N/A')}\n\n"
                    f"**Qtd de Pacotes:**\n{report_data.get('total_pacotes', 'N/A')}\n"
                    f"**Varia√ß√£o Pacotes:**\n{report_data.get('variacao_pacotes', 'N/A')}"
                )}},
            {"is_short": True, "text": {"tag": "lark_md",
                "content": (
                    f"**Multa Atual:**\n{report_data.get('multa_atual', 'N/A')}\n"
                    f"**Varia√ß√£o Multa:**\n{report_data.get('variacao_multa', 'N/A')}"
                )}}
        ]},
        {"tag": "hr"},
        {"tag": "div", "text": {"tag": "lark_md", "content": report_data.get("metrics_text", "")}},
        {"tag": "hr"},
        {"tag": "action", "actions": [
            {"tag": "button",
             "text": {"tag": "plain_text", "content": "üìé Abrir Relat√≥rio Completo"},
             "url": LINK_RELATORIO,
             "type": "primary"}
        ]},
        {"tag": "note", "elements": [{"tag": "plain_text", "content": report_data.get("observation", "")}]}
    ]

    return {
        "msg_type": "interactive",
        "card": {
            "header": {
                "title": {"tag": "plain_text", "content": f"üö® Sem Movimenta√ß√£o - {report_data.get('title', '')}"},
                "template": "red"   # üî¥ Header vermelho
            },
            "elements": elements
        }
    }


# ==============================================================================
# FUN√á√ïES DE ENVIO E PROCESSAMENTO
# ==============================================================================

def send_report_to_feishu(webhook_url: str, report_data: Dict[str, Any]):
    headers = {"Content-Type": "application/json"}
    payload = create_feishu_card_payload(report_data)
    try:
        r = requests.post(webhook_url, headers=headers, data=json.dumps(payload))
        r.raise_for_status()
        print(f"‚úÖ Enviado para {webhook_url[:50]}...")
    except Exception as e:
        print(f"‚ùå Erro ao enviar: {e}")


def process_report_file(file_path: str) -> Optional[pd.DataFrame]:
    try:
        return pd.read_excel(file_path)
    except Exception as e:
        print(f"Erro ao ler {file_path}: {e}")
        return None


def dispatch_reports_by_coordinator(df: pd.DataFrame, report_title: str):
    if "Coordenadores" not in df.columns:
        print("‚ö†Ô∏è Coluna 'Coordenadores' n√£o encontrada.")
        return

    df_old = carregar_ultimo_arquivo_morto()

    for coordenador, webhook_url in COORDENADOR_WEBHOOKS.items():
        df_coord = df[df["Coordenadores"] == coordenador]
        if df_coord.empty:
            continue

        df_coord_old = None
        if df_old is not None and "Coordenadores" in df_old.columns:
            df_coord_old = df_old[df_old["Coordenadores"] == coordenador]

        report_data = prepare_report_data(df_coord, df_coord_old, f"{coordenador}")
        report_data["date"] = datetime.now().strftime("%d/%m/%Y %H:%M")

        send_report_to_feishu(webhook_url, report_data)
        time.sleep(1)


# ==============================================================================
# EXECU√á√ÉO PRINCIPAL
# ==============================================================================

def run_main_task():
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Procurando relat√≥rios em {REPORTS_FOLDER_PATH}")

    arquivos = [
        f for f in os.listdir(REPORTS_FOLDER_PATH)
        if f.endswith(".xlsx") and "5+ dias" in f and not f.startswith("~")
    ]
    if not arquivos:
        print("‚ö†Ô∏è Nenhum relat√≥rio encontrado.")
        return

    arquivos.sort(key=lambda x: os.path.getmtime(os.path.join(REPORTS_FOLDER_PATH, x)), reverse=True)
    file_name = arquivos[0]

    full_path = os.path.join(REPORTS_FOLDER_PATH, file_name)
    df_current = process_report_file(full_path)
    if df_current is not None:
        dispatch_reports_by_coordinator(df_current, os.path.splitext(file_name)[0])


if __name__ == "__main__":
    run_main_task()